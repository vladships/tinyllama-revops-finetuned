{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rW68TUQe4Fig"
      },
      "outputs": [],
      "source": [
        "# ============================================================================\n",
        "# CELL 1: Install Required Libraries\n",
        "# ============================================================================\n",
        "# This installs all the packages we need for fine-tuning\n",
        "# Takes about 1-2 minutes\n",
        "\n",
        "!pip install -q transformers accelerate bitsandbytes peft datasets"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================================\n",
        "# CELL 2: Load Base Model and Tokenizer\n",
        "# ============================================================================\n",
        "# This loads TinyLlama (1.1B parameters) - a small but capable model\n",
        "# We use 4-bit quantization to save memory (load_in_4bit=True)\n",
        "\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "import torch\n",
        "\n",
        "BASE_MODEL = \"TinyLlama/TinyLlama-1.1B-Chat-v1.0\"\n",
        "\n",
        "print(\"Loading tokenizer and model...\")\n",
        "tokenizer = AutoTokenizer.from_pretrained(BASE_MODEL, use_fast=True)\n",
        "tokenizer.pad_token = tokenizer.eos_token  # Required for batching\n",
        "\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    BASE_MODEL,\n",
        "    device_map=\"auto\",\n",
        "    load_in_4bit=True,\n",
        "    torch_dtype=torch.float16\n",
        ")\n",
        "\n",
        "print(\"‚úì Model loaded successfully!\")\n",
        "print(f\"Model is on device: {model.device}\")"
      ],
      "metadata": {
        "id": "gsZkDq935zHn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================================\n",
        "# CELL 3: Create Training Dataset\n",
        "# ============================================================================\n",
        "# 50 examples covering Salesforce Agentforce, NetSuite AI, and SaaS Revenue (ASC 606)\n",
        "\n",
        "training_data = [\n",
        "    # SALESFORCE AGENTFORCE (20 examples)\n",
        "    {\n",
        "        \"instruction\": \"What is Salesforce Agentforce?\",\n",
        "        \"output\": \"Agentforce is Salesforce's autonomous AI agent platform that allows businesses to build and deploy AI agents to handle tasks like customer service, sales, and operations without human intervention.\"\n",
        "    },\n",
        "    {\n",
        "        \"instruction\": \"What are the main types of Agentforce agents?\",\n",
        "        \"output\": \"The main types are Service Agent for customer support, Sales Development Representative (SDR) Agent for lead qualification, Personal Shopper Agent for e-commerce, and Campaign Agent for marketing automation.\"\n",
        "    },\n",
        "    {\n",
        "        \"instruction\": \"How do Agentforce topics work?\",\n",
        "        \"output\": \"Topics define what an agent knows about. They're configured with data sources, instructions, and guardrails. When a user asks a question, the agent uses RAG to retrieve relevant information from topics to generate responses.\"\n",
        "    },\n",
        "    {\n",
        "        \"instruction\": \"What is RAG in Agentforce?\",\n",
        "        \"output\": \"RAG stands for Retrieval Augmented Generation. It allows agents to search through your company data in real-time and use that context to generate accurate, grounded responses rather than relying solely on the LLM's training.\"\n",
        "    },\n",
        "    {\n",
        "        \"instruction\": \"How do you trigger an Agentforce agent?\",\n",
        "        \"output\": \"Agents can be triggered through multiple channels: Einstein Copilot, Flow automation, Apex code, Experience Cloud sites, or API calls. You configure triggers based on business logic like case creation or time-based events.\"\n",
        "    },\n",
        "    {\n",
        "        \"instruction\": \"What are Agentforce guardrails?\",\n",
        "        \"output\": \"Guardrails are safety controls that prevent agents from taking unwanted actions. They include data access controls, action permissions, approval requirements, and content filters to ensure agents operate within defined boundaries.\"\n",
        "    },\n",
        "    {\n",
        "        \"instruction\": \"Can Agentforce agents escalate to humans?\",\n",
        "        \"output\": \"Yes, agents can automatically escalate to human agents based on rules like customer sentiment, complexity thresholds, specific keywords, or when the agent's confidence score falls below a set level.\"\n",
        "    },\n",
        "    {\n",
        "        \"instruction\": \"How does Agentforce handle multiple languages?\",\n",
        "        \"output\": \"Agentforce supports multilingual interactions through Einstein's language detection and translation capabilities. Agents can detect the user's language and respond accordingly, or you can configure language-specific topics.\"\n",
        "    },\n",
        "    {\n",
        "        \"instruction\": \"What data sources can Agentforce access?\",\n",
        "        \"output\": \"Agents can access Salesforce objects, Knowledge articles, external data via MuleSoft or APIs, Data Cloud, document repositories, and custom data sources configured through Flow or Apex.\"\n",
        "    },\n",
        "    {\n",
        "        \"instruction\": \"How do you measure Agentforce performance?\",\n",
        "        \"output\": \"Use Agent Analytics to track metrics like resolution rate, average handling time, CSAT scores, escalation rate, accuracy of responses, and conversation volume. These are available in the Einstein Trust Layer dashboard.\"\n",
        "    },\n",
        "    {\n",
        "        \"instruction\": \"What is the Einstein Trust Layer?\",\n",
        "        \"output\": \"The Einstein Trust Layer is Salesforce's security architecture for AI. It includes data masking, zero retention policies with LLM providers, toxicity detection, audit logs, and ensures your data isn't used to train external models.\"\n",
        "    },\n",
        "    {\n",
        "        \"instruction\": \"Can you customize Agentforce prompts?\",\n",
        "        \"output\": \"Yes, you can customize system prompts, topic instructions, and response templates through Prompt Builder. This allows you to control the agent's tone, format, and specific behaviors for your use case.\"\n",
        "    },\n",
        "    {\n",
        "        \"instruction\": \"How does Agentforce integrate with Flow?\",\n",
        "        \"output\": \"Agents can invoke Flow actions to perform complex operations like updating records, sending emails, or calling external systems. Flows can also trigger agents based on business logic or schedule.\"\n",
        "    },\n",
        "    {\n",
        "        \"instruction\": \"What's the difference between Einstein Copilot and Agentforce?\",\n",
        "        \"output\": \"Einstein Copilot is an AI assistant that helps users within Salesforce with recommendations and automation. Agentforce agents are autonomous and can handle end-to-end processes independently, including customer-facing interactions.\"\n",
        "    },\n",
        "    {\n",
        "        \"instruction\": \"How do you handle agent authentication?\",\n",
        "        \"output\": \"Agents inherit permissions from their configured service account or use guest user profiles for public-facing agents. You control data access through profiles, permission sets, and sharing rules like any Salesforce user.\"\n",
        "    },\n",
        "    {\n",
        "        \"instruction\": \"Can Agentforce agents learn from interactions?\",\n",
        "        \"output\": \"Agents improve through feedback loops where human reviews, CSAT ratings, and correction data are fed back into the system. This helps refine topics, prompts, and retrieval accuracy over time.\"\n",
        "    },\n",
        "    {\n",
        "        \"instruction\": \"What's required to deploy an Agentforce agent?\",\n",
        "        \"output\": \"You need Einstein 1 license, configured topics with data sources, defined triggers and channels, set guardrails and permissions, tested responses, and established monitoring and escalation paths.\"\n",
        "    },\n",
        "    {\n",
        "        \"instruction\": \"How does Agentforce handle unstructured data?\",\n",
        "        \"output\": \"Agents use semantic search and vector embeddings to understand unstructured content like PDFs, emails, and chat transcripts. The RAG system converts queries and documents into embeddings to find relevant context.\"\n",
        "    },\n",
        "    {\n",
        "        \"instruction\": \"What are Agentforce action groups?\",\n",
        "        \"output\": \"Action groups are collections of related actions an agent can perform, like 'Case Management' actions including create case, update status, and send notification. They help organize and control agent capabilities.\"\n",
        "    },\n",
        "    {\n",
        "        \"instruction\": \"Can you A/B test Agentforce configurations?\",\n",
        "        \"output\": \"Yes, you can create multiple versions of topics or prompts and route traffic between them. Use Agent Analytics to compare performance metrics and determine which configuration performs better.\"\n",
        "    },\n",
        "\n",
        "    # NETSUITE AI & AUTOMATION (15 examples)\n",
        "    {\n",
        "        \"instruction\": \"What AI features does NetSuite offer in 2025?\",\n",
        "        \"output\": \"NetSuite offers Text Enhancer for AI-generated item descriptions, Intelligent Recommendations for next-best actions, Analytics Warehouse with ML predictions, Document Processing automation, and Smart Alerts for anomaly detection.\"\n",
        "    },\n",
        "    {\n",
        "        \"instruction\": \"What is NetSuite Text Enhancer?\",\n",
        "        \"output\": \"Text Enhancer uses generative AI to automatically create product descriptions, marketing copy, and item details from minimal input. It helps maintain consistency and saves time on catalog management.\"\n",
        "    },\n",
        "    {\n",
        "        \"instruction\": \"How does NetSuite Analytics Warehouse use ML?\",\n",
        "        \"output\": \"Analytics Warehouse applies machine learning to historical data to generate demand forecasts, identify trends, predict cash flow, and surface anomalies. It provides predictive insights within dashboards and reports.\"\n",
        "    },\n",
        "    {\n",
        "        \"instruction\": \"What is NetSuite Intelligent Recommendations?\",\n",
        "        \"output\": \"It's an AI system that suggests next-best actions to users based on context, like recommending approval workflows, suggesting reorder points, or highlighting exceptions that need attention.\"\n",
        "    },\n",
        "    {\n",
        "        \"instruction\": \"How does NetSuite automate document processing?\",\n",
        "        \"output\": \"NetSuite uses OCR and AI to extract data from invoices, receipts, and purchase orders automatically. It can match documents to transactions, validate data, and route for approval without manual entry.\"\n",
        "    },\n",
        "    {\n",
        "        \"instruction\": \"Can NetSuite predict inventory needs?\",\n",
        "        \"output\": \"Yes, through Analytics Warehouse and demand planning features. It analyzes historical sales, seasonality, and trends to forecast future demand and recommend optimal stock levels and reorder points.\"\n",
        "    },\n",
        "    {\n",
        "        \"instruction\": \"What are NetSuite Smart Alerts?\",\n",
        "        \"output\": \"Smart Alerts use anomaly detection to notify users of unusual patterns like unexpected expense spikes, revenue drops, or inventory discrepancies. They help catch issues before they become problems.\"\n",
        "    },\n",
        "    {\n",
        "        \"instruction\": \"How does NetSuite handle multi-subsidiary automation?\",\n",
        "        \"output\": \"NetSuite's OneWorld feature automates intercompany transactions, currency conversions, and consolidation across subsidiaries. AI recommendations help optimize transfer pricing and identify consolidation exceptions.\"\n",
        "    },\n",
        "    {\n",
        "        \"instruction\": \"What is SuiteAnalytics Connect?\",\n",
        "        \"output\": \"It's a JDBC/ODBC driver that allows external BI tools and AI platforms to query NetSuite data directly. This enables integration with advanced analytics and ML tools outside NetSuite.\"\n",
        "    },\n",
        "    {\n",
        "        \"instruction\": \"Can NetSuite automate revenue recognition?\",\n",
        "        \"output\": \"Yes, NetSuite's Advanced Revenue Management module automates ASC 606 compliance by creating revenue schedules, handling performance obligations, and generating recognition entries based on configured rules.\"\n",
        "    },\n",
        "    {\n",
        "        \"instruction\": \"How does NetSuite AI improve quote-to-cash?\",\n",
        "        \"output\": \"AI features streamline CPQ with smart product recommendations, automated pricing, contract generation using templates, and intelligent approval routing. Analytics predict deal closure probability and identify bottlenecks.\"\n",
        "    },\n",
        "    {\n",
        "        \"instruction\": \"What machine learning models does NetSuite use?\",\n",
        "        \"output\": \"NetSuite primarily uses time-series forecasting models, classification algorithms for document processing, clustering for customer segmentation, and anomaly detection models for alerts.\"\n",
        "    },\n",
        "    {\n",
        "        \"instruction\": \"Can you train custom AI models in NetSuite?\",\n",
        "        \"output\": \"NetSuite doesn't support custom model training natively. However, you can integrate external ML platforms via SuiteCloud Platform, REST APIs, or SuiteAnalytics Connect to apply custom models to NetSuite data.\"\n",
        "    },\n",
        "    {\n",
        "        \"instruction\": \"How does NetSuite ensure AI data security?\",\n",
        "        \"output\": \"NetSuite applies role-based access controls to AI features, encrypts data in transit and at rest, maintains SOC 2 compliance, and ensures AI processing doesn't expose data beyond user permissions.\"\n",
        "    },\n",
        "    {\n",
        "        \"instruction\": \"What's new in NetSuite's 2025 AI roadmap?\",\n",
        "        \"output\": \"NetSuite is expanding generative AI for report creation, natural language querying of data, enhanced forecasting models, and deeper integration with analytics tools. Focus is on making ERP more intuitive and predictive.\"\n",
        "    },\n",
        "\n",
        "    # SAAS REVENUE - ASC 606 (15 examples)\n",
        "    {\n",
        "        \"instruction\": \"What is ASC 606?\",\n",
        "        \"output\": \"ASC 606 is the revenue recognition standard that requires companies to recognize revenue when control of goods or services transfers to the customer, not simply when cash is received. It replaced ASC 605 in 2018.\"\n",
        "    },\n",
        "    {\n",
        "        \"instruction\": \"What are the 5 steps of ASC 606?\",\n",
        "        \"output\": \"The five steps are: 1) Identify the contract with a customer, 2) Identify performance obligations, 3) Determine the transaction price, 4) Allocate price to performance obligations, 5) Recognize revenue when obligations are satisfied.\"\n",
        "    },\n",
        "    {\n",
        "        \"instruction\": \"What is a performance obligation in ASC 606?\",\n",
        "        \"output\": \"A performance obligation is a promise to transfer a distinct good or service to a customer. In SaaS, common obligations include software access, implementation services, training, and ongoing support.\"\n",
        "    },\n",
        "    {\n",
        "        \"instruction\": \"How do you recognize SaaS subscription revenue under ASC 606?\",\n",
        "        \"output\": \"SaaS subscriptions are typically recognized ratably over the subscription period because the performance obligation (providing software access) is satisfied over time as the customer consumes the service.\"\n",
        "    },\n",
        "    {\n",
        "        \"instruction\": \"What is deferred revenue?\",\n",
        "        \"output\": \"Deferred revenue is cash received from customers for services not yet delivered. It's recorded as a liability on the balance sheet and recognized as revenue when the performance obligation is satisfied.\"\n",
        "    },\n",
        "    {\n",
        "        \"instruction\": \"How do you handle upfront implementation fees under ASC 606?\",\n",
        "        \"output\": \"If implementation creates a distinct service, recognize revenue when complete. If it's not distinct from the SaaS subscription, defer the fee and recognize it over the subscription term along with subscription revenue.\"\n",
        "    },\n",
        "    {\n",
        "        \"instruction\": \"What is the difference between ARR and revenue?\",\n",
        "        \"output\": \"ARR (Annual Recurring Revenue) is a forward-looking metric showing annualized contract value. Revenue is what's actually recognized per GAAP based on performance obligations satisfied. ARR helps predict future revenue.\"\n",
        "    },\n",
        "    {\n",
        "        \"instruction\": \"How do you allocate transaction price in multi-element arrangements?\",\n",
        "        \"output\": \"Allocate the total contract price to each performance obligation based on standalone selling prices (SSP). If SSP isn't observable, estimate it using cost-plus, market assessment, or residual approaches.\"\n",
        "    },\n",
        "    {\n",
        "        \"instruction\": \"What triggers a contract modification under ASC 606?\",\n",
        "        \"output\": \"A modification occurs when contract scope or price changes and both parties approve. Treat it as a separate contract if it adds distinct goods/services at SSP. Otherwise, adjust the existing contract prospectively or retrospectively.\"\n",
        "    },\n",
        "    {\n",
        "        \"instruction\": \"How do you handle variable consideration in SaaS?\",\n",
        "        \"output\": \"Include variable consideration (like usage fees or performance bonuses) in transaction price only to the extent it's probable that a significant revenue reversal won't occur. Update estimates each period.\"\n",
        "    },\n",
        "    {\n",
        "        \"instruction\": \"What is MRR in SaaS businesses?\",\n",
        "        \"output\": \"MRR (Monthly Recurring Revenue) is the normalized monthly value of all active subscriptions. It's calculated by dividing annual contracts by 12 and summing all monthly subscriptions. MRR helps track business momentum.\"\n",
        "    },\n",
        "    {\n",
        "        \"instruction\": \"How do you recognize revenue for usage-based pricing?\",\n",
        "        \"output\": \"Recognize usage-based revenue as the customer uses the service, since that's when the performance obligation is satisfied. This requires tracking actual usage and applying the contracted rates each period.\"\n",
        "    },\n",
        "    {\n",
        "        \"instruction\": \"What are contract assets vs receivables under ASC 606?\",\n",
        "        \"output\": \"A receivable is an unconditional right to payment. A contract asset is revenue recognized before you have an unconditional right to payment (like when performance precedes billing milestones).\"\n",
        "    },\n",
        "    {\n",
        "        \"instruction\": \"How do refund provisions affect revenue recognition?\",\n",
        "        \"output\": \"Refund provisions create variable consideration. Estimate expected refunds using historical data and reduce revenue recognized accordingly. Update the estimate each period and adjust revenue if expectations change.\"\n",
        "    },\n",
        "    {\n",
        "        \"instruction\": \"What is the practical expedient for contract costs?\",\n",
        "        \"output\": \"ASC 606 allows expensing contract acquisition costs immediately if the amortization period would be one year or less. This simplifies accounting for monthly or short-term SaaS contracts.\"\n",
        "    }\n",
        "]\n",
        "\n",
        "print(f\"‚úì Created training dataset with {len(training_data)} examples\")\n",
        "print(f\"  - Salesforce Agentforce: 20 examples\")\n",
        "print(f\"  - NetSuite AI: 15 examples\")\n",
        "print(f\"  - SaaS Revenue (ASC 606): 15 examples\\n\")"
      ],
      "metadata": {
        "id": "4bn2JOW16O2b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================================\n",
        "# CELL 4: Prepare Model and Train with LoRA\n",
        "# ============================================================================\n",
        "# LoRA (Low-Rank Adaptation) is an efficient fine-tuning method\n",
        "# Instead of updating all 1.1B parameters, we add small adapter layers\n",
        "# This is much faster and uses less memory\n",
        "\n",
        "from peft import LoraConfig, get_peft_model, prepare_model_for_kbit_training\n",
        "from transformers import Trainer, TrainingArguments\n",
        "import torch\n",
        "import os\n",
        "\n",
        "# Disable wandb to avoid API key prompts\n",
        "os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
        "\n",
        "# Format data as conversational prompts\n",
        "def format_instruction(example):\n",
        "    return f\"User: {example['instruction']}\\nAssistant: {example['output']}\"\n",
        "\n",
        "formatted_texts = [format_instruction(ex) for ex in training_data]\n",
        "\n",
        "# Tokenize all examples\n",
        "print(\"Tokenizing training data...\")\n",
        "encodings = tokenizer(\n",
        "    formatted_texts,\n",
        "    padding=\"max_length\",\n",
        "    truncation=True,\n",
        "    max_length=256,  # Shorter for faster training\n",
        "    return_tensors=\"pt\"\n",
        ")\n",
        "\n",
        "# Create PyTorch dataset with labels\n",
        "class InstructionDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, encodings):\n",
        "        self.input_ids = encodings[\"input_ids\"]\n",
        "        self.attention_mask = encodings[\"attention_mask\"]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.input_ids)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return {\n",
        "            \"input_ids\": self.input_ids[idx],\n",
        "            \"attention_mask\": self.attention_mask[idx],\n",
        "            \"labels\": self.input_ids[idx].clone()  # For causal LM, labels = input_ids\n",
        "        }\n",
        "\n",
        "train_dataset = InstructionDataset(encodings)\n",
        "print(f\"‚úì Dataset ready with {len(train_dataset)} examples\\n\")\n",
        "\n",
        "# Prepare model for LoRA training\n",
        "print(\"Preparing model for LoRA fine-tuning...\")\n",
        "model.gradient_checkpointing_enable()\n",
        "model = prepare_model_for_kbit_training(model)\n",
        "\n",
        "# LoRA configuration - these are the adapter parameters\n",
        "lora_config = LoraConfig(\n",
        "    r=8,  # Rank of the adapter matrices\n",
        "    lora_alpha=16,  # Scaling factor\n",
        "    lora_dropout=0.05,  # Dropout for regularization\n",
        "    bias=\"none\",\n",
        "    task_type=\"CAUSAL_LM\",\n",
        "    target_modules=[\"q_proj\", \"v_proj\"]  # Which layers to add adapters to\n",
        ")\n",
        "\n",
        "model = get_peft_model(model, lora_config)\n",
        "model.print_trainable_parameters()  # Shows we're only training ~0.1% of parameters\n",
        "\n",
        "# Training configuration\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./training_output\",\n",
        "    num_train_epochs=3,  # Number of times to go through the dataset\n",
        "    per_device_train_batch_size=1,  # Smaller batch size for stability\n",
        "    gradient_accumulation_steps=4,  # Effective batch size = 1 * 4 = 4\n",
        "    learning_rate=2e-4,\n",
        "    fp16=True,  # Use mixed precision for speed\n",
        "    logging_steps=5,\n",
        "    save_strategy=\"no\",  # Don't save checkpoints during training\n",
        "    optim=\"paged_adamw_8bit\",  # Memory-efficient optimizer\n",
        "    report_to=\"none\"  # Disable reporting to wandb/tensorboard\n",
        ")\n",
        "\n",
        "# Create trainer and start training\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset\n",
        ")\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"STARTING TRAINING - This will take about 5-10 minutes\")\n",
        "print(\"=\"*60 + \"\\n\")\n",
        "\n",
        "trainer.train()\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"‚úì TRAINING COMPLETE!\")\n",
        "print(\"=\"*60 + \"\\n\")"
      ],
      "metadata": {
        "id": "bXoKjPtJ6TxN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================================\n",
        "# CELL 5: Test the Fine-Tuned Model and Save Everything\n",
        "# ============================================================================\n",
        "\n",
        "print(\"Testing the fine-tuned model...\\n\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# Put model in evaluation mode\n",
        "model.eval()\n",
        "\n",
        "# Test with questions from each domain\n",
        "test_questions = [\n",
        "    \"User: What is RAG in Agentforce?\\nAssistant:\",\n",
        "    \"User: What is NetSuite Text Enhancer?\\nAssistant:\",\n",
        "    \"User: What are the 5 steps of ASC 606?\\nAssistant:\",\n",
        "    \"User: How do you recognize SaaS subscription revenue?\\nAssistant:\"\n",
        "]\n",
        "\n",
        "for question in test_questions:\n",
        "    print(f\"\\nüìù Question: {question.split('Assistant:')[0].replace('User: ', '').strip()}\")\n",
        "\n",
        "    inputs = tokenizer(question, return_tensors=\"pt\").to(model.device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        outputs = model.generate(\n",
        "            **inputs,\n",
        "            max_new_tokens=100,\n",
        "            temperature=0.7,\n",
        "            do_sample=True,\n",
        "            top_p=0.9,\n",
        "            pad_token_id=tokenizer.eos_token_id\n",
        "        )\n",
        "\n",
        "    response = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "    # Extract just the assistant's response\n",
        "    assistant_response = response.split(\"Assistant:\")[-1].strip()\n",
        "    print(f\"ü§ñ Answer: {assistant_response}\")\n",
        "    print(\"-\" * 60)\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"SAVING MODEL\")\n",
        "print(\"=\"*60 + \"\\n\")\n",
        "\n",
        "# Save the LoRA adapter and tokenizer\n",
        "SAVE_DIR = \"tinyllama-revops-finetuned\"\n",
        "\n",
        "model.save_pretrained(SAVE_DIR)\n",
        "tokenizer.save_pretrained(SAVE_DIR)\n",
        "\n",
        "print(f\"‚úì Model saved to './{SAVE_DIR}/'\")\n",
        "print(\"\\nWhat was saved:\")\n",
        "print(\"  - adapter_config.json (LoRA configuration)\")\n",
        "print(\"  - adapter_model.safetensors (trained weights)\")\n",
        "print(\"  - tokenizer files\")\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"‚úÖ ALL DONE!\")\n",
        "print(\"=\"*60)\n",
        "print(\"\\nNext steps:\")\n",
        "print(\"1. Download the folder from Colab (Files tab on left)\")\n",
        "print(\"2. Create a GitHub repo and upload these files\")\n",
        "print(\"3. Add a README.md explaining your project\")\n",
        "print(\"4. Post on LinkedIn with examples of the model's responses!\")\n",
        "print(\"\\nThe base model is TinyLlama-1.1B-Chat-v1.0\")\n",
        "print(\"Your fine-tuned adapter is ready to share! üöÄ\")"
      ],
      "metadata": {
        "id": "aNchLNjU6yga"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!zip -r tinyllama-revops-finetuned.zip tinyllama-revops-finetuned"
      ],
      "metadata": {
        "id": "xu3DIrC18Skd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# CELL 6 ‚Äî Upload to Hugging Face (safe; upload-only)\n",
        "!pip -q install huggingface_hub\n",
        "from huggingface_hub import login, create_repo, upload_folder\n",
        "\n",
        "login()  # paste token in the popup\n",
        "REPO_ID = \"Builder123/tinyllama-revops-finetuned\"   # change if you prefer\n",
        "\n",
        "create_repo(REPO_ID, repo_type=\"model\", exist_ok=True)\n",
        "upload_folder(repo_id=REPO_ID, folder_path=\"tinyllama-revops-finetuned\")\n",
        "\n",
        "print(\"Done ‚Üí https://huggingface.co/\" + REPO_ID)\n"
      ],
      "metadata": {
        "id": "nuhklMb4GwmH"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}